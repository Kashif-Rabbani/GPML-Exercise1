{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pagerank.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh6Sb-8Gaxm4"
      },
      "source": [
        "# Pagerank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYWJ2YwGcQTK"
      },
      "source": [
        "Authored by:\n",
        "* Emil Riis Hansen \n",
        "* Jonas Brusokas\n",
        "* Kashif Rabbani\n",
        "\n",
        "References:\n",
        "* Pagerank docs from Networkx - https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html\n",
        "* General algorithm and references to relevant material - https://en.wikipedia.org/wiki/PageRank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fzok5xQb6aE"
      },
      "source": [
        "## Installing Python preliminaries\n",
        "* networkx - library for working with graphs\n",
        "* matplotlib - plotting library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKvAs2l6KPo3"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/joerg84/Graph_Powered_ML_Workshop.git\n",
        "!rsync -av Graph_Powered_ML_Workshop/ ./ --exclude=.git\n",
        "!pip3 install networkx\n",
        "!pip3 install matplotlib"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2fzFFn6KIYD"
      },
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUZ2wec8Knb1"
      },
      "source": [
        "## Pagerank algorithm implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZC378QyKmZO"
      },
      "source": [
        "# Handy method for extracting list of elements from list of tuples by position\n",
        "def map_tuple_pos(list_of_tuples, pos):\n",
        "  return list(map(lambda tuple: tuple[pos], list_of_tuples))\n",
        "\n",
        "# Calculate page rank on given directed graph\n",
        "# orig_dg - graph\n",
        "# d - dampening parameter\n",
        "# t - max number of iterations\n",
        "def pagerank(orig_dg: nx.DiGraph, d: float = 0.85, t: int = 100):\n",
        "\n",
        "  def out_nodes(curr_node):\n",
        "    outgoing_nodes = map_tuple_pos(dg.out_edges(curr_node),1)\n",
        "    return outgoing_nodes\n",
        "    \n",
        "  def in_nodes(curr_node):\n",
        "    return map_tuple_pos(dg.in_edges(curr_node), 0)\n",
        "\n",
        "  def factor(curr_node):\n",
        "    return sum(map(lambda in_node: old_pr_dict[in_node] / len(out_nodes(in_node)),in_nodes(curr_node)))\n",
        "\n",
        "  # Copy the graph to prevent modification of the original\n",
        "  dg = orig_dg.copy()\n",
        "\n",
        "  # Find dangling nodes and connect them to all others\n",
        "  for node in dg.nodes:\n",
        "    if (len(out_nodes(node)) == 0):\n",
        "      new_edges = list(map(lambda nodeTo: (node, nodeTo), list(dg.nodes)))\n",
        "      dg.add_edges_from(new_edges)\n",
        "\n",
        "  pr_dict = {}\n",
        "  N = len(dg.nodes)\n",
        "\n",
        "  # Initial PR 1/N\n",
        "  for node in dg.nodes:\n",
        "    pr_dict[node] = 1./len(dg.nodes)\n",
        "\n",
        "  # Number of iterations / timesteps [0..t)\n",
        "  for _ in range(t):\n",
        "    old_pr_dict = pr_dict.copy()\n",
        "    for node in dg.nodes:\n",
        "      pr_dict[node] = (1. - d)/N + d * factor(node)\n",
        "      # print(f\"Factor: {factor(node)}\")\n",
        "\n",
        "  return pr_dict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQZs08HneDXA"
      },
      "source": [
        "## Test code\n",
        "- Generates random graphs and computes, compares reference pagerank and notebook implementations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG_fOeTCLFdP",
        "outputId": "c5234a0f-56f6-4c45-f048-2fe028a0048b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "common_d = 0.85\n",
        "common_t = 100\n",
        "\n",
        "graph_error_tuples = []\n",
        "\n",
        "for n in range(10):\n",
        "  for p in [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]:\n",
        "    gg = nx.gnp_random_graph(n, p, seed=1, directed=True).to_directed()\n",
        "    my_pr = pagerank(gg, common_d, common_t)\n",
        "    ref_pr = nx.pagerank(gg, alpha=common_d, max_iter=common_t)\n",
        "    error = sum(map(lambda key: abs(my_pr[key] - ref_pr[key]), list(ref_pr.keys())))\n",
        "    graph_error_tuples.append( (gg, error) )\n",
        "\n",
        "error_list = map_tuple_pos(graph_error_tuples, 1)\n",
        "print(\"Error between networkx reference implementation and the notebook implementation\")\n",
        "print(f\"Minimum error: {min(error_list)}\")\n",
        "print(f\"Maximum error: {max(error_list)}\")\n",
        "print(f\"Average error: {sum(error_list) / len(error_list)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error between networkx reference implementation and the notebook implementation\n",
            "Minimum error: 0\n",
            "Maximum error: 3.362070030051012e-06\n",
            "Average error: 6.3476070791494e-07\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}