{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Node classification with SAGE",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzXakuIRcQTG"
      },
      "source": [
        "# Node classification with SAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYWJ2YwGcQTK"
      },
      "source": [
        "Authored by:\n",
        "* Emil Riis Hansen \n",
        "* Jonas Brusokas\n",
        "* Kashif Rabbani\n",
        "\n",
        "References:\n",
        "* General experiment setup - StellarGraph SAGE demo: https://stellargraph.readthedocs.io/en/stable/demos/node-classification/graphsage-node-classification.html\n",
        "* NN setup with DGL - https://docs.dgl.ai/guide/training-node.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufe2NfI-cqX4"
      },
      "source": [
        "### Installing Python preliminaries\n",
        "* StellarGraph (hosts the preprocessed graph representation of the original dataset)\n",
        "* Pandas, numpy, ... - default PyData libraries\n",
        "* SKLearn - data preprocessing\n",
        "* DGL - for GNN model definition, training and etc. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbsphinx": "hidden",
        "tags": [
          "CloudRunner"
        ],
        "id": "ZkIGh3f9cQTL",
        "outputId": "2340914d-9e6a-4f66-fa8f-99f570169f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# install StellarGraph if running on Google Colab\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  %pip install -q stellargraph[demos]==1.2.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 440kB 4.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 11.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25h  Building wheel for mplleaflet (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbsphinx": "hidden",
        "tags": [
          "VersionCheck"
        ],
        "id": "PlN5ETeTcQTY"
      },
      "source": [
        "# verify that we're using the correct version of StellarGraph for this notebook\n",
        "import stellargraph as sg\n",
        "\n",
        "try:\n",
        "    sg.utils.validate_notebook_version(\"1.2.1\")\n",
        "except AttributeError:\n",
        "    raise ValueError(\n",
        "        f\"This notebook requires StellarGraph version 1.2.1, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n",
        "    ) from None"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Km6mOVpEcQTe"
      },
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import json\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from networkx.readwrite import json_graph\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import stellargraph as sg\n",
        "from stellargraph.mapper import ClusterNodeGenerator\n",
        "from stellargraph.layer import GCN\n",
        "from stellargraph import globalvar\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
        "from sklearn import preprocessing, feature_extraction, model_selection\n",
        "from stellargraph import datasets\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6PXGdJ_SwHn",
        "outputId": "13ae5c3e-07e9-48a5-aa06-b3f53a9712aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "!pip install dgl\n",
        "\n",
        "# Specific dependencies for DGL with PyTorch acting as a back-end\n",
        "# NOTE: PyTorch is the default back-end \n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/05/9627fd225854f9ab77984f79405e78def50eb673a962940ed30fc07e9ac6/dgl-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.5.2\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B567XdxWcQTl"
      },
      "source": [
        "## Loading the dataset\n",
        "\n",
        "This notebook demonstrates the DGL SAGE implementation for classification. It uses the Cora dataset of classified scientific publications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd9MKCwRcQTm",
        "outputId": "0beb6f6f-aec6-46d8-fb43-128e3aa3a7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "display(HTML(datasets.Cora().description))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "DataLoading"
        ],
        "id": "VUO-ukojcQTu",
        "outputId": "043804e8-42ad-479c-a75b-be9d4fbcebf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "G, labels = datasets.Cora().load()\n",
        "\n",
        "print(G.info())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 2708, Edges: 5429\n",
            "\n",
            " Node types:\n",
            "  paper: [2708]\n",
            "    Features: float32 vector, length 1433\n",
            "    Edge types: paper-cites->paper\n",
            "\n",
            " Edge types:\n",
            "    paper-cites->paper: [5429]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7vmSFnUWEr0"
      },
      "source": [
        "As seen from the G.info output, the Graph has 2708 nodes, 5429 edges. Each node has 1433 features (corresponding to words from dictionary)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABuCSEUncQT7",
        "outputId": "cbbcf432-026c-4a5c-9d9d-8d262faa3625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "set(labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Case_Based',\n",
              " 'Genetic_Algorithms',\n",
              " 'Neural_Networks',\n",
              " 'Probabilistic_Methods',\n",
              " 'Reinforcement_Learning',\n",
              " 'Rule_Learning',\n",
              " 'Theory'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fhl21NSWYXI"
      },
      "source": [
        "There are 7 distinct target classes, classifying type of scientific publication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwkcZ6cEcQUL",
        "outputId": "674fb82c-8fcd-4bcb-f59c-44323c0b1c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "from collections import Counter\n",
        "Counter(labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Case_Based': 298,\n",
              "         'Genetic_Algorithms': 418,\n",
              "         'Neural_Networks': 818,\n",
              "         'Probabilistic_Methods': 426,\n",
              "         'Reinforcement_Learning': 217,\n",
              "         'Rule_Learning': 180,\n",
              "         'Theory': 351})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_0ri_vZWxNK"
      },
      "source": [
        "There is a imbalance of classes within the dataset that might lead to sub-optimal predictive performance, but for the purposes of demonstrating how GNNs work, it will suffice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW8A_aryV523"
      },
      "source": [
        "## Graph preprocessing for DGL | PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSWYwpj9O-Ja",
        "outputId": "01416418-95d4-412f-aa70-4dccaca70705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(f\"Number of nodes in graph: {len(G.nodes())}\")\n",
        "\n",
        "# Create a tensor of shape [nodes, features] where for each node (corresponding to a paper), identify which words from dictionary it contains\n",
        "node_features = torch.from_numpy(G.node_features())\n",
        "print(f\"Extracted node features tensor shape: {node_features.shape}\")\n",
        "\n",
        "# Create one-hot encoded vectors for labels (targets | paper classes) \n",
        "target_encoding = preprocessing.LabelBinarizer()\n",
        "one_hot_node_labels = target_encoding.fit_transform(labels)\n",
        "print(f\"Extracted node one-hot encoded labels tensor shape: {one_hot_node_labels.shape}\")\n",
        "\n",
        "# For the defined model we want to have labels as integers (position of '1' within one-hot encoded vector)\n",
        "node_labels = torch.from_numpy(np.argmax(one_hot_node_labels, axis=1))\n",
        "print(f\"Extracted node labels tensor shape: {node_labels.shape}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of nodes in graph: 2708\n",
            "Extracted node features tensor shape: torch.Size([2708, 1433])\n",
            "Extracted node one-hot encoded labels tensor shape: (2708, 7)\n",
            "Extracted node labels tensor shape: torch.Size([2708])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLvdLn0oedi_"
      },
      "source": [
        "## Constructing a SAGE NN (2-layer) for node classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxhmY-C5eAJa"
      },
      "source": [
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super().__init__()\n",
        "        print(f\"SAGE Model constructed: in_feats={in_feats}, hid_feats={hid_feats}, out_feats={out_feats}\")\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        # inputs are features of nodes\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        # Model returns a tensor of probabilities - shape [node_count, output_features (categories)]\n",
        "        return h"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykemAHqmbjIE"
      },
      "source": [
        "### Defining necessary preliminaries (node, feature, label counts and converting graph to DGL graph)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2bwhYHTeoM4",
        "outputId": "d042dcc7-8114-44dd-a5f2-2b4cb634aebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "n_nodes = node_features.shape[0]\n",
        "n_features = node_features.shape[1]\n",
        "n_labels = int(node_labels.max().item() + 1)\n",
        "\n",
        "print(f\"Number of nodes: {n_nodes}\")\n",
        "print(f\"Number of features: {n_features}\")\n",
        "print(f\"Number of labels (classes): {n_labels}\")\n",
        "\n",
        "nx_graph = G.to_networkx()\n",
        "graph = dgl.from_networkx(nx_graph)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of nodes: 2708\n",
            "Number of features: 1433\n",
            "Number of labels (classes): 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xR5yIjUbrBk"
      },
      "source": [
        "### Defining which nodes will be used for training, validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkgDWghRZjXb"
      },
      "source": [
        "n_train_nodes = 100\n",
        "n_valid_nodes = 500\n",
        "n_test_nodes = 1000\n",
        "\n",
        "# We divide the dataset (by using bool masks as identifiers) as follows:\n",
        "# [100 training nodes] [500 validation nodes] [1000 test nodes] [all other (1108) nodes]\n",
        "train_mask = torch.tensor([True] * n_train_nodes + [False] * (n_nodes - n_train_nodes))\n",
        "valid_mask = torch.tensor([False] * n_train_nodes + [True] * n_valid_nodes + [False] * (n_nodes - n_train_nodes - n_valid_nodes))\n",
        "test_mask = torch.tensor([False] * n_train_nodes + [False] * n_valid_nodes + [True] * (n_test_nodes) + [False] * (n_nodes - n_train_nodes - n_valid_nodes - n_test_nodes))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Gfewwmbvt_"
      },
      "source": [
        "### Defining our evaluation metric (correct/all predictions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7VjsDrFeqkK"
      },
      "source": [
        "def evaluate(model, graph, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(graph, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        \n",
        "        # Our evaluation metric is the ratio of correct_predictions/all_predictions\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcm1kXZSb1tu"
      },
      "source": [
        "### Training code (model, optimizer instantiation, training loop)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzu4HaeIeuBB",
        "outputId": "bafb241c-44b9-43c9-90d4-8dacdd98a17d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "model = SAGE(in_feats=n_features, hid_feats=100, out_feats=n_labels)\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "epoch_count = 20\n",
        "\n",
        "print(\"\\n--- [Training started] --- \")\n",
        "for epoch in range(epoch_count):\n",
        "    model.train()\n",
        "    # Forward propagation by using all nodes - generates prediction\n",
        "    logits = model(graph, node_features)\n",
        "\n",
        "    # Compute loss from the training data\n",
        "    # NOTE: mask defines which subset of the data to use for loss calculation\n",
        "    loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
        "\n",
        "    # Compute validation accuracy\n",
        "    acc = evaluate(model, graph, node_features, node_labels, valid_mask)\n",
        "\n",
        "    # Backward propagation\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1} | training loss: {loss.item()}, validation accuracy: {acc}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SAGE Model constructed: in_feats=1433, hid_feats=100, out_feats=7\n",
            "\n",
            "--- [Training started] --- \n",
            "Epoch: 1 | training loss: 2.013437271118164, validation accuracy: 0.116\n",
            "Epoch: 2 | training loss: 1.8030956983566284, validation accuracy: 0.138\n",
            "Epoch: 3 | training loss: 1.6141239404678345, validation accuracy: 0.168\n",
            "Epoch: 4 | training loss: 1.443945288658142, validation accuracy: 0.21\n",
            "Epoch: 5 | training loss: 1.290073037147522, validation accuracy: 0.244\n",
            "Epoch: 6 | training loss: 1.1508654356002808, validation accuracy: 0.266\n",
            "Epoch: 7 | training loss: 1.0245959758758545, validation accuracy: 0.292\n",
            "Epoch: 8 | training loss: 0.9097762107849121, validation accuracy: 0.308\n",
            "Epoch: 9 | training loss: 0.8051037788391113, validation accuracy: 0.326\n",
            "Epoch: 10 | training loss: 0.7101536393165588, validation accuracy: 0.342\n",
            "Epoch: 11 | training loss: 0.6242868900299072, validation accuracy: 0.356\n",
            "Epoch: 12 | training loss: 0.54667067527771, validation accuracy: 0.36\n",
            "Epoch: 13 | training loss: 0.4772014617919922, validation accuracy: 0.368\n",
            "Epoch: 14 | training loss: 0.41529205441474915, validation accuracy: 0.378\n",
            "Epoch: 15 | training loss: 0.36047735810279846, validation accuracy: 0.378\n",
            "Epoch: 16 | training loss: 0.31242835521698, validation accuracy: 0.38\n",
            "Epoch: 17 | training loss: 0.2706632912158966, validation accuracy: 0.39\n",
            "Epoch: 18 | training loss: 0.23443637788295746, validation accuracy: 0.39\n",
            "Epoch: 19 | training loss: 0.2031077742576599, validation accuracy: 0.396\n",
            "Epoch: 20 | training loss: 0.17599855363368988, validation accuracy: 0.394\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}